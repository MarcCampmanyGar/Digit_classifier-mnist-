{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Digit classify.ipynb",
      "provenance": [],
      "toc_visible": true,
      "mount_file_id": "1kyg6KXAG99uHzo6E1EaxmBxlwx3E8PXZ",
      "authorship_tag": "ABX9TyNSWpVYxJ82pzU0b3EI7tRh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MarcCampmanyGar/Digit_classifier-mnist-/blob/main/Digit_classify.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QFdNL0xl6EcH"
      },
      "source": [
        "import pandas as pd\r\n",
        "import numpy as np\r\n",
        "import tensorflow as tf\r\n",
        "from PIL import Image\r\n",
        "import os\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import keras\r\n",
        "from functools import partial\r\n",
        "from keras.models import Sequential, load_model\r\n",
        "from keras.layers import Dense, Input, Dropout\r\n",
        "from keras.callbacks import ReduceLROnPlateau, ModelCheckpoint\r\n",
        "\r\n",
        "%matplotlib inline\r\n",
        "np.random.seed(1)"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vNhTA2u1-rIc"
      },
      "source": [
        "#Importing the training and testing data\r\n",
        "training_set = pd.read_csv(\"/content/sample_data/mnist_train_small.csv\")\r\n",
        "testing_set = pd.read_csv(\"/content/sample_data/mnist_test.csv\")"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h_-u91tD1waf",
        "outputId": "dccf0be7-2296-4cf0-a8fc-499841d6625b"
      },
      "source": [
        "training_set.columns"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['6', '0', '0.1', '0.2', '0.3', '0.4', '0.5', '0.6', '0.7', '0.8',\n",
              "       ...\n",
              "       '0.581', '0.582', '0.583', '0.584', '0.585', '0.586', '0.587', '0.588',\n",
              "       '0.589', '0.590'],\n",
              "      dtype='object', length=785)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J2wNej6-Lp-Y",
        "outputId": "228a4543-d876-43bc-bd17-3539677ba64c"
      },
      "source": [
        "#Let's split the label and the pixel values from the training data\r\n",
        "X_train = training_set.drop(['6'], axis=1).values.reshape(training_set.shape[0], 28, 28, 1)\r\n",
        "y_train = training_set['6'].copy()\r\n",
        "\r\n",
        "print(\"The shape of X_train is : \", X_train.shape)\r\n",
        "print(\"The shape of y_train is : \", y_train.shape)\r\n",
        "print(\"The shape of testing_set is : \", testing_set.shape)\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The shape of X_train is :  (19999, 28, 28, 1)\n",
            "The shape of y_train is :  (19999,)\n",
            "The shape of testing_set is :  (9999, 785)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Fu5cBfLOgjq",
        "outputId": "4b6443a4-8c2b-4c28-fa09-a73ca6293a66"
      },
      "source": [
        "#It is important to have a validation set to assess the model's performance.\r\n",
        "#We will be creating a validation set which contains atleast 6,800 images.\r\n",
        "\r\n",
        "#first shuffling the dataset\r\n",
        "shuffled_indices = np.random.permutation(19999)\r\n",
        "X_train = X_train[shuffled_indices]\r\n",
        "y_train = y_train[shuffled_indices]\r\n",
        "\r\n",
        "#Creating a validation set from the last 6,800 images\r\n",
        "X_train, X_valid = X_train[:13199], X_train[13199:]\r\n",
        "y_train, y_valid = y_train[:13199], y_train[13199:]\r\n",
        "\r\n",
        "print(\"The shape of X_train is : \", X_train.shape)\r\n",
        "print(\"The shape of y_train is : \", y_train.shape)\r\n",
        "print(\"The shape of X_valid is : \", X_valid.shape)\r\n",
        "print(\"The shape of y_valid is : \", y_valid.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The shape of X_train is :  (13199, 28, 28, 1)\n",
            "The shape of y_train is :  (13199,)\n",
            "The shape of X_valid is :  (6800, 28, 28, 1)\n",
            "The shape of y_valid is :  (6800,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 338
        },
        "id": "lMHe2O28VWTM",
        "outputId": "6bd0cf8e-4599-417a-d136-8ddcabaccb5b"
      },
      "source": [
        "random_num = np.random.random_integers(1,6800)\r\n",
        "plt.imshow(X_train[random_num].reshape(28, 28))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: DeprecationWarning: This function is deprecated. Please call randint(1, 6800 + 1) instead\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f8400b24a58>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4mwKvUytPknA",
        "outputId": "f13a2df5-7b48-4efe-96c5-d274542e088a"
      },
      "source": [
        "#Let's see how many images are there per class(digit)\r\n",
        "\r\n",
        "print(y_train.value_counts())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1    1461\n",
            "7    1362\n",
            "3    1357\n",
            "6    1349\n",
            "9    1341\n",
            "2    1313\n",
            "0    1307\n",
            "4    1281\n",
            "8    1247\n",
            "5    1181\n",
            "Name: 6, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eiF9DZV2Px1C"
      },
      "source": [
        "#Each class has around 1100 to 1400 images. So the chance of class imbalance is less\r\n",
        "#Create a basic Convolutional Neural Network model\r\n",
        "\r\n",
        "DefaultConv2D = partial(keras.layers.Conv2D, kernel_size=3, activation='relu', padding='same')\r\n",
        "Digit_Recognizer = Sequential([\r\n",
        "                        DefaultConv2D(filters=64, kernel_size=7, input_shape=[28, 28, 1]),\r\n",
        "                        keras.layers.MaxPooling2D(pool_size=2),\r\n",
        "                        DefaultConv2D(filters=128),\r\n",
        "                        DefaultConv2D(filters=128),\r\n",
        "                        keras.layers.MaxPooling2D(pool_size=2),\r\n",
        "                        DefaultConv2D(filters=256),\r\n",
        "                        DefaultConv2D(filters=256),\r\n",
        "                        keras.layers.MaxPooling2D(pool_size=2),\r\n",
        "                        keras.layers.Flatten(),\r\n",
        "                        Dense(units=128, activation='relu'),\r\n",
        "                        Dropout(0.5),\r\n",
        "                        Dense(units=64, activation='relu'),\r\n",
        "                        Dropout(0.5),\r\n",
        "                        Dense(units=10, activation='softmax'),\r\n",
        "                   ])\r\n",
        "\r\n",
        "Digit_Recognizer.compile(optimizer=\"nadam\", loss=\"sparse_categorical_crossentropy\", metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aqCBF7g2QRPC",
        "outputId": "fd50aaf0-3126-4bd0-f2c8-3d4c60b8d610"
      },
      "source": [
        "#Summarizing the model\r\n",
        "Digit_Recognizer.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_5 (Conv2D)            (None, 28, 28, 64)        3200      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 14, 14, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_6 (Conv2D)            (None, 14, 14, 128)       73856     \n",
            "_________________________________________________________________\n",
            "conv2d_7 (Conv2D)            (None, 14, 14, 128)       147584    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2 (None, 7, 7, 128)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_8 (Conv2D)            (None, 7, 7, 256)         295168    \n",
            "_________________________________________________________________\n",
            "conv2d_9 (Conv2D)            (None, 7, 7, 256)         590080    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_5 (MaxPooling2 (None, 3, 3, 256)         0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 2304)              0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 128)               295040    \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 64)                8256      \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 10)                650       \n",
            "=================================================================\n",
            "Total params: 1,413,834\n",
            "Trainable params: 1,413,834\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sZWt-ZhIQVEy",
        "outputId": "66a03497-032b-4e76-aee4-914be3c366e4"
      },
      "source": [
        "#Training the model\r\n",
        "filepath = \"./model.h5\"\r\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='accuracy', verbose=1, \r\n",
        "                             save_best_only=True, mode='max')\r\n",
        "\r\n",
        "reduce_lr = ReduceLROnPlateau(monitor='accuracy', factor=0.5, patience=2, \r\n",
        "                                   verbose=1, mode='max', min_lr=0.00001)\r\n",
        "                              \r\n",
        "                              \r\n",
        "callbacks_list = [checkpoint, reduce_lr]\r\n",
        "history = Digit_Recognizer.fit(X_train, y_train, epochs=30, batch_size=64, validation_data=(X_valid, y_valid), \r\n",
        "                     verbose=1, callbacks=callbacks_list)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "204/207 [============================>.] - ETA: 0s - loss: 1.6789 - accuracy: 0.4368\n",
            "Epoch 00001: accuracy improved from -inf to 0.43988, saving model to ./model.h5\n",
            "207/207 [==============================] - 3s 14ms/step - loss: 1.6708 - accuracy: 0.4399 - val_loss: 0.3005 - val_accuracy: 0.9394\n",
            "Epoch 2/30\n",
            "206/207 [============================>.] - ETA: 0s - loss: 0.5556 - accuracy: 0.8254\n",
            "Epoch 00002: accuracy improved from 0.43988 to 0.82552, saving model to ./model.h5\n",
            "207/207 [==============================] - 3s 13ms/step - loss: 0.5552 - accuracy: 0.8255 - val_loss: 0.1636 - val_accuracy: 0.9550\n",
            "Epoch 3/30\n",
            "205/207 [============================>.] - ETA: 0s - loss: 0.3757 - accuracy: 0.8950\n",
            "Epoch 00003: accuracy improved from 0.82552 to 0.89514, saving model to ./model.h5\n",
            "207/207 [==============================] - 3s 14ms/step - loss: 0.3749 - accuracy: 0.8951 - val_loss: 0.1258 - val_accuracy: 0.9709\n",
            "Epoch 4/30\n",
            "205/207 [============================>.] - ETA: 0s - loss: 0.2749 - accuracy: 0.9259\n",
            "Epoch 00004: accuracy improved from 0.89514 to 0.92590, saving model to ./model.h5\n",
            "207/207 [==============================] - 3s 14ms/step - loss: 0.2760 - accuracy: 0.9259 - val_loss: 0.1334 - val_accuracy: 0.9675\n",
            "Epoch 5/30\n",
            "205/207 [============================>.] - ETA: 0s - loss: 0.2354 - accuracy: 0.9412\n",
            "Epoch 00005: accuracy improved from 0.92590 to 0.94113, saving model to ./model.h5\n",
            "207/207 [==============================] - 3s 14ms/step - loss: 0.2354 - accuracy: 0.9411 - val_loss: 0.0833 - val_accuracy: 0.9825\n",
            "Epoch 6/30\n",
            "205/207 [============================>.] - ETA: 0s - loss: 0.2062 - accuracy: 0.9486\n",
            "Epoch 00006: accuracy improved from 0.94113 to 0.94841, saving model to ./model.h5\n",
            "207/207 [==============================] - 3s 14ms/step - loss: 0.2061 - accuracy: 0.9484 - val_loss: 0.1104 - val_accuracy: 0.9784\n",
            "Epoch 7/30\n",
            "206/207 [============================>.] - ETA: 0s - loss: 0.1924 - accuracy: 0.9549\n",
            "Epoch 00007: accuracy improved from 0.94841 to 0.95492, saving model to ./model.h5\n",
            "207/207 [==============================] - 3s 14ms/step - loss: 0.1922 - accuracy: 0.9549 - val_loss: 0.0760 - val_accuracy: 0.9835\n",
            "Epoch 8/30\n",
            "206/207 [============================>.] - ETA: 0s - loss: 0.1555 - accuracy: 0.9622\n",
            "Epoch 00008: accuracy improved from 0.95492 to 0.96212, saving model to ./model.h5\n",
            "207/207 [==============================] - 3s 14ms/step - loss: 0.1557 - accuracy: 0.9621 - val_loss: 0.0929 - val_accuracy: 0.9809\n",
            "Epoch 9/30\n",
            "206/207 [============================>.] - ETA: 0s - loss: 0.1533 - accuracy: 0.9637\n",
            "Epoch 00009: accuracy improved from 0.96212 to 0.96363, saving model to ./model.h5\n",
            "207/207 [==============================] - 3s 14ms/step - loss: 0.1533 - accuracy: 0.9636 - val_loss: 0.0895 - val_accuracy: 0.9824\n",
            "Epoch 10/30\n",
            "206/207 [============================>.] - ETA: 0s - loss: 0.1322 - accuracy: 0.9691\n",
            "Epoch 00010: accuracy improved from 0.96363 to 0.96901, saving model to ./model.h5\n",
            "207/207 [==============================] - 3s 13ms/step - loss: 0.1322 - accuracy: 0.9690 - val_loss: 0.4037 - val_accuracy: 0.9290\n",
            "Epoch 11/30\n",
            "206/207 [============================>.] - ETA: 0s - loss: 0.1270 - accuracy: 0.9725\n",
            "Epoch 00011: accuracy improved from 0.96901 to 0.97250, saving model to ./model.h5\n",
            "207/207 [==============================] - 3s 13ms/step - loss: 0.1269 - accuracy: 0.9725 - val_loss: 0.0899 - val_accuracy: 0.9832\n",
            "Epoch 12/30\n",
            "205/207 [============================>.] - ETA: 0s - loss: 0.1028 - accuracy: 0.9753\n",
            "Epoch 00012: accuracy improved from 0.97250 to 0.97538, saving model to ./model.h5\n",
            "207/207 [==============================] - 3s 13ms/step - loss: 0.1024 - accuracy: 0.9754 - val_loss: 0.1125 - val_accuracy: 0.9816\n",
            "Epoch 13/30\n",
            "206/207 [============================>.] - ETA: 0s - loss: 0.1261 - accuracy: 0.9703\n",
            "Epoch 00013: accuracy did not improve from 0.97538\n",
            "207/207 [==============================] - 3s 13ms/step - loss: 0.1266 - accuracy: 0.9703 - val_loss: 0.1118 - val_accuracy: 0.9828\n",
            "Epoch 14/30\n",
            "206/207 [============================>.] - ETA: 0s - loss: 0.0892 - accuracy: 0.9784\n",
            "Epoch 00014: accuracy improved from 0.97538 to 0.97841, saving model to ./model.h5\n",
            "207/207 [==============================] - 3s 13ms/step - loss: 0.0891 - accuracy: 0.9784 - val_loss: 0.0916 - val_accuracy: 0.9860\n",
            "Epoch 15/30\n",
            "205/207 [============================>.] - ETA: 0s - loss: 0.0944 - accuracy: 0.9784\n",
            "Epoch 00015: accuracy did not improve from 0.97841\n",
            "207/207 [==============================] - 3s 13ms/step - loss: 0.0948 - accuracy: 0.9783 - val_loss: 0.2011 - val_accuracy: 0.9637\n",
            "Epoch 16/30\n",
            "206/207 [============================>.] - ETA: 0s - loss: 0.1058 - accuracy: 0.9772\n",
            "Epoch 00016: accuracy did not improve from 0.97841\n",
            "\n",
            "Epoch 00016: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "207/207 [==============================] - 3s 13ms/step - loss: 0.1058 - accuracy: 0.9772 - val_loss: 0.1288 - val_accuracy: 0.9816\n",
            "Epoch 17/30\n",
            "206/207 [============================>.] - ETA: 0s - loss: 0.0653 - accuracy: 0.9851\n",
            "Epoch 00017: accuracy improved from 0.97841 to 0.98515, saving model to ./model.h5\n",
            "207/207 [==============================] - 3s 13ms/step - loss: 0.0652 - accuracy: 0.9852 - val_loss: 0.0872 - val_accuracy: 0.9865\n",
            "Epoch 18/30\n",
            "205/207 [============================>.] - ETA: 0s - loss: 0.0380 - accuracy: 0.9909\n",
            "Epoch 00018: accuracy improved from 0.98515 to 0.99098, saving model to ./model.h5\n",
            "207/207 [==============================] - 3s 13ms/step - loss: 0.0379 - accuracy: 0.9910 - val_loss: 0.0879 - val_accuracy: 0.9869\n",
            "Epoch 19/30\n",
            "205/207 [============================>.] - ETA: 0s - loss: 0.0354 - accuracy: 0.9921\n",
            "Epoch 00019: accuracy improved from 0.99098 to 0.99220, saving model to ./model.h5\n",
            "207/207 [==============================] - 3s 13ms/step - loss: 0.0352 - accuracy: 0.9922 - val_loss: 0.0753 - val_accuracy: 0.9891\n",
            "Epoch 20/30\n",
            "205/207 [============================>.] - ETA: 0s - loss: 0.0311 - accuracy: 0.9934\n",
            "Epoch 00020: accuracy improved from 0.99220 to 0.99326, saving model to ./model.h5\n",
            "207/207 [==============================] - 3s 13ms/step - loss: 0.0314 - accuracy: 0.9933 - val_loss: 0.0892 - val_accuracy: 0.9875\n",
            "Epoch 21/30\n",
            "206/207 [============================>.] - ETA: 0s - loss: 0.0414 - accuracy: 0.9901\n",
            "Epoch 00021: accuracy did not improve from 0.99326\n",
            "207/207 [==============================] - 3s 13ms/step - loss: 0.0413 - accuracy: 0.9901 - val_loss: 0.1056 - val_accuracy: 0.9881\n",
            "Epoch 22/30\n",
            "206/207 [============================>.] - ETA: 0s - loss: 0.0637 - accuracy: 0.9867\n",
            "Epoch 00022: accuracy did not improve from 0.99326\n",
            "\n",
            "Epoch 00022: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "207/207 [==============================] - 3s 13ms/step - loss: 0.0636 - accuracy: 0.9867 - val_loss: 0.1129 - val_accuracy: 0.9834\n",
            "Epoch 23/30\n",
            "205/207 [============================>.] - ETA: 0s - loss: 0.0349 - accuracy: 0.9905\n",
            "Epoch 00023: accuracy did not improve from 0.99326\n",
            "207/207 [==============================] - 3s 13ms/step - loss: 0.0347 - accuracy: 0.9905 - val_loss: 0.1063 - val_accuracy: 0.9874\n",
            "Epoch 24/30\n",
            "206/207 [============================>.] - ETA: 0s - loss: 0.0277 - accuracy: 0.9944\n",
            "Epoch 00024: accuracy improved from 0.99326 to 0.99439, saving model to ./model.h5\n",
            "207/207 [==============================] - 3s 13ms/step - loss: 0.0277 - accuracy: 0.9944 - val_loss: 0.1027 - val_accuracy: 0.9881\n",
            "Epoch 25/30\n",
            "204/207 [============================>.] - ETA: 0s - loss: 0.0279 - accuracy: 0.9935\n",
            "Epoch 00025: accuracy did not improve from 0.99439\n",
            "207/207 [==============================] - 3s 13ms/step - loss: 0.0279 - accuracy: 0.9935 - val_loss: 0.0908 - val_accuracy: 0.9874\n",
            "Epoch 26/30\n",
            "206/207 [============================>.] - ETA: 0s - loss: 0.0247 - accuracy: 0.9940\n",
            "Epoch 00026: accuracy did not improve from 0.99439\n",
            "\n",
            "Epoch 00026: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
            "207/207 [==============================] - 3s 13ms/step - loss: 0.0247 - accuracy: 0.9940 - val_loss: 0.0925 - val_accuracy: 0.9890\n",
            "Epoch 27/30\n",
            "206/207 [============================>.] - ETA: 0s - loss: 0.0269 - accuracy: 0.9937\n",
            "Epoch 00027: accuracy did not improve from 0.99439\n",
            "207/207 [==============================] - 3s 13ms/step - loss: 0.0269 - accuracy: 0.9937 - val_loss: 0.0878 - val_accuracy: 0.9897\n",
            "Epoch 28/30\n",
            "204/207 [============================>.] - ETA: 0s - loss: 0.0244 - accuracy: 0.9933\n",
            "Epoch 00028: accuracy did not improve from 0.99439\n",
            "\n",
            "Epoch 00028: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
            "207/207 [==============================] - 3s 13ms/step - loss: 0.0251 - accuracy: 0.9933 - val_loss: 0.0892 - val_accuracy: 0.9901\n",
            "Epoch 29/30\n",
            "204/207 [============================>.] - ETA: 0s - loss: 0.0195 - accuracy: 0.9952\n",
            "Epoch 00029: accuracy improved from 0.99439 to 0.99515, saving model to ./model.h5\n",
            "207/207 [==============================] - 3s 13ms/step - loss: 0.0196 - accuracy: 0.9952 - val_loss: 0.0928 - val_accuracy: 0.9897\n",
            "Epoch 30/30\n",
            "205/207 [============================>.] - ETA: 0s - loss: 0.0194 - accuracy: 0.9954\n",
            "Epoch 00030: accuracy improved from 0.99515 to 0.99538, saving model to ./model.h5\n",
            "207/207 [==============================] - 3s 13ms/step - loss: 0.0193 - accuracy: 0.9954 - val_loss: 0.0939 - val_accuracy: 0.9900\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304
        },
        "id": "v_p2vK-vT3n0",
        "outputId": "f61dd2b5-a098-4211-a883-4f337b1a958c"
      },
      "source": [
        "#testing on an image\r\n",
        "Digit_Recognizer = load_model('./model.h5')     #Loading the best model\r\n",
        "plt.imshow(X_valid[3993].reshape(28, 28))\r\n",
        "print(\"The digit recognized by the model is : \", Digit_Recognizer.predict_classes(X_valid[3993].reshape(1, 28, 28, 1)))\r\n",
        "plt.axis('off')\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:10 out of the last 10 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f83f8bb07b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "The digit recognized by the model is :  [2]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Edejl2i_Uqjc"
      },
      "source": [
        "#The model predicts with almost 99.2% validation accuracy\r\n",
        "#test_predictions = pd.DataFrame(Digit_Recognizer.predict_classes(testing_set), index=range(1, 28001))\r\n",
        "#test_predictions.to_csv('./Submissions.csv', index_label=['ImageId', 'Label'])"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}